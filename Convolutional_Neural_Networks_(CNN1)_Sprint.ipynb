{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPODePSFfXyB5I72YM+RPq+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ismael-rtellez/CNN1_Series_Assignment/blob/main/Convolutional_Neural_Networks_(CNN1)_Sprint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN1 Series Assignment: SimpleConv1d"
      ],
      "metadata": {
        "id": "vPgS3zmteKDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Problem 1] Creating a one-dimensional convolutional layer class that limits the number of channels to one"
      ],
      "metadata": {
        "id": "Q6iLnvkxeUJN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TS_Q6kEMjTSU"
      },
      "outputs": [],
      "source": [
        "# Problem 1: Creating a one-dimensional convolutional layer classtaht limits the number of channels to one\n",
        "import numpy as np\n",
        "\n",
        "class SimpleConv1d:\n",
        "    def __init__(self, filter_size):\n",
        "        self.filter_size = filter_size\n",
        "        # Xavier initialization\n",
        "        scale = np.sqrt(1.0 / filter_size)\n",
        "        self.W = np.random.randn(filter_size) * scale\n",
        "        self.B = np.zeros(1)\n",
        "        self.dW = None\n",
        "        self.dB = None\n",
        "        self.learning_rate = 0.01\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        self.output_size = len(x) - self.filter_size + 1\n",
        "        self.a = np.zeros(self.output_size)\n",
        "        for i in range(self.output_size):\n",
        "            self.a[i] = np.sum(x[i:i+self.filter_size] * self.W) + self.B\n",
        "        return self.a\n",
        "\n",
        "    def backward(self, delta_a):\n",
        "        self.dW = np.zeros_like(self.W)\n",
        "        self.dB = np.sum(delta_a)\n",
        "        self.dx = np.zeros_like(self.x)\n",
        "\n",
        "        for s in range(self.filter_size):\n",
        "            for i in range(self.output_size):\n",
        "                self.dW[s] += delta_a[i] * self.x[i + s]\n",
        "\n",
        "        for j in range(len(self.x)):\n",
        "            for s in range(self.filter_size):\n",
        "                if 0 <= j - s < self.output_size:\n",
        "                    self.dx[j] += delta_a[j - s] * self.W[s]\n",
        "\n",
        "        return self.dx\n",
        "\n",
        "    def update(self):\n",
        "        self.W -= self.learning_rate * self.dW\n",
        "        self.B -= self.learning_rate * self.dB"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Problem 2] Output size calculation after one-dimensional convolution"
      ],
      "metadata": {
        "id": "LKMeRI7beZWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 2: Output size calculation after one-dimensional convolution\n",
        "def calculate_conv1d_output_size(n_input, padding, filter_size, stride):\n",
        "    return (n_input + 2 * padding - filter_size) // stride + 1"
      ],
      "metadata": {
        "id": "rMc36Huby2TV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Problem 3] Experiment of one-dimensional convolutional layer with small array"
      ],
      "metadata": {
        "id": "0hJO3Pyyecyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 3: Experiment of one-dimensional convolutional layer with small array\n",
        "x = np.array([1, 2, 3, 4])\n",
        "w = np.array([3, 5, 7])\n",
        "b = np.array([1])\n",
        "\n",
        "conv = SimpleConv1d(filter_size=3)\n",
        "conv.W = w.copy()\n",
        "conv.B = b.copy()\n",
        "\n",
        "# Forward\n",
        "a = conv.forward(x)\n",
        "print(\"Forward output: \", a)\n",
        "\n",
        "# Backward\n",
        "delta_a = np.array([10, 20])\n",
        "dx = conv.backward(delta_a)\n",
        "print(\"dW: \", conv.dW)\n",
        "print(\"dB: \", conv.dB)\n",
        "print(\"dx: \", dx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpduMasizVF9",
        "outputId": "91b39648-9779-43dc-d1b9-9cd181c10d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forward output:  [35. 50.]\n",
            "dW:  [ 50  80 110]\n",
            "dB:  30\n",
            "dx:  [ 30 110 170 140]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-741684474.py:20: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  self.a[i] = np.sum(x[i:i+self.filter_size] * self.W) + self.B\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Problem 4] Creating a one-dimensional convolutional layer class that does not limit the number of channels"
      ],
      "metadata": {
        "id": "U1BpD4bcegJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 4: Creating a one-dimensional convolutional layer classthat does not limit the number of channels\n",
        "\n",
        "class Conv1d:\n",
        "    def __init__(self, in_channels, out_channels, filter_size):\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.filter_size = filter_size\n",
        "        scale = np.sqrt(1.0 / (in_channels * filter_size))\n",
        "        self.W = np.random.randn(out_channels, in_channels, filter_size) * scale\n",
        "        self.B = np.zeros(out_channels)\n",
        "        self.dW = None\n",
        "        self.dB = None\n",
        "        self.learning_rate = 0.01\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        in_channels, n_features = x.shape\n",
        "        out_features = n_features - self.filter_size + 1\n",
        "        self.out_features = out_features\n",
        "        self.a = np.zeros((self.out_channels, out_features))\n",
        "\n",
        "        for oc in range(self.out_channels):\n",
        "            for i in range(out_features):\n",
        "                for ic in range(self.in_channels):\n",
        "                    self.a[oc, i] += np.sum(\n",
        "                        x[ic, i:i+self.filter_size] * self.W[oc, ic]\n",
        "                        )\n",
        "                self.a[oc, i] += self.B[oc]\n",
        "        return self.a\n"
      ],
      "metadata": {
        "id": "_9sjbjd5zNjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Problem 5] (Advanced task) Implementing padding"
      ],
      "metadata": {
        "id": "rkuJKtV3ejkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 5: (Advanced task) Implementing padding\n",
        "def pad1d(x, pad_with, mode='constant'):\n",
        "    return np.pad(x, pad_with, mode=mode)\n",
        "\n",
        "# running an example to see output\n",
        "x = np.array([1, 2, 3, 4])\n",
        "print(\"Padded: \", pad1d(x, (2, 2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUWTju6H22ay",
        "outputId": "b2bfbc9d-8f7c-48c3-a5d7-8706689cf029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padded:  [0 0 1 2 3 4 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Problem 6] (Advanced task) Response to mini batch"
      ],
      "metadata": {
        "id": "ZMblZAg7emHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 6: (Advanced Task) Response to mini batch\n",
        "\n",
        "def forward(self, x):   # x shape: (batch_size, in_channels, n_features)\n",
        "    self.x = x\n",
        "    batch_size, in_channels, n_features = x.shape\n",
        "    out_features = n_features - self.filter_size + 1\n",
        "    self.out_features = out_features\n",
        "    self.a = np.zeros((batch_size, self.out_channels, out_features))\n",
        "\n",
        "    for b in range(batch_size):\n",
        "        for oc in range(self.out_channels):\n",
        "            for i in range(out_features):\n",
        "                for ic in range(self.in_channels):\n",
        "                    self.a[b, oc, i] += np.sum(\n",
        "                        x[b, ic, i:i+self.filter_size] * self.W[oc, ic]\n",
        "                        )\n",
        "                self.a[b, oc, i] += self.B[oc]\n",
        "    return self.a"
      ],
      "metadata": {
        "id": "StC8y9wp5MJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Problem 7] (Advance assignment) Arbitrary number of strides"
      ],
      "metadata": {
        "id": "29O6kod5eo0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 7: (Advance assignment) Arbitrary number of strides\n",
        "def forward(self, x, stride=1):\n",
        "    self.stride = stride\n",
        "    self.x = x\n",
        "    batch_size, in_channels, n_features = x.shape\n",
        "    out_features = (n_features - self.filter_size) // stride + 1\n",
        "    self.out_features = out_features\n",
        "    self.a = np.zeros((batch_size, self.out_channels, out_features))\n",
        "\n",
        "    for b in range(batch_size):\n",
        "        for oc in range(self.out_channels):\n",
        "            for i in range(out_features):\n",
        "                start = i * stride\n",
        "                for ic in range(self.in_channels):\n",
        "                    self.a[b, oc, i] += np.sum(\n",
        "                        x[b, ic, start:start + self.filter_size] * self.W[oc, ic]\n",
        "                        )\n",
        "                self.a[b, oc, i] += self.B[oc]\n",
        "    return self.a"
      ],
      "metadata": {
        "id": "jBSgV3Dm6H4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Problem 8] Learning and estimation"
      ],
      "metadata": {
        "id": "KIQB236LereW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 8: Learning and estimation\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# utilities\n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "    return e_x / e_x.sum(axis=1, keepdims=True)\n",
        "\n",
        "def cross_entropy(y_pred, y_true):\n",
        "    return -np.sum(y_true * np.log(y_pred + 1e-7)) / y_true.shape[0]\n",
        "\n",
        "def softmax_cross_entropy_grad(y_pred, y_true):\n",
        "    return (y_pred - y_true) / y_true.shape[0]\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_grad(x):\n",
        "    return (x > 0).astype(np.float32)\n",
        "\n",
        "# Conv1d layer\n",
        "class Conv1d_p8:\n",
        "    def __init__(self, in_channels, out_channels, filter_size):\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.filter_size = filter_size\n",
        "        scale = np.sqrt(1.0 / (in_channels * filter_size))\n",
        "        self.W = np.random.randn(out_channels, in_channels, filter_size) * scale\n",
        "        self.B = np.zeros(out_channels)\n",
        "        self.dW = None\n",
        "        self.dB = None\n",
        "        self.lr = 0.01\n",
        "\n",
        "    def forward(self, x, stride=1):\n",
        "        self.stride = stride\n",
        "        self.x = x\n",
        "        batch_size, in_channels, n_features = x.shape\n",
        "        self.out_features = (n_features - self.W.shape[2]) // stride + 1\n",
        "        self.a = np.zeros((batch_size, self.W.shape[0], self.out_features))\n",
        "        for b in range(batch_size):\n",
        "            for oc in range(self.W.shape[0]):\n",
        "                for i in range(self.out_features):\n",
        "                    start = i * stride\n",
        "                    for ic in range(self.W.shape[1]):\n",
        "                        self.a[b, oc, i] += np.sum(\n",
        "                            x[b, ic, start:start + self.W.shape[2]] * self.W[oc, ic]\n",
        "                            )\n",
        "                    self.a[b, oc, i] += self.B[oc]\n",
        "        return self.a\n",
        "\n",
        "    def backward(self, delta):\n",
        "        batch_size, in_channels, n_features = self.x.shape\n",
        "        _, out_channels, _ = delta.shape\n",
        "        filter_size = self.W.shape[2]\n",
        "\n",
        "        self.dW = np.zeros_like(self.W)\n",
        "        self.dB = np.zeros_like(self.B)\n",
        "        dx = np.zeros_like(self.x)\n",
        "\n",
        "        for b in range(batch_size):\n",
        "            for oc in range(out_channels):\n",
        "                for i in range(self.out_features):\n",
        "                    start = i * self.stride\n",
        "                    self.dB[oc] += delta[b, oc, i]\n",
        "                    for ic in range(in_channels):\n",
        "                        self.dW[oc, ic] += self.x[b, ic, start:start + filter_size] * delta[b, oc, i]\n",
        "                        dx[b, ic, start:start + filter_size] += self.W[oc, ic] * delta[b, oc, i]\n",
        "\n",
        "        self.W -= self.lr * self.dW\n",
        "        self.B -= self.lr * self.dB\n",
        "        return dx\n",
        "\n",
        "# Fully Connected layer\n",
        "class FC:\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        scale = np.sqrt(1.0 / input_dim)\n",
        "        self.W = np.random.randn(input_dim, output_dim) * scale\n",
        "        self.B = np.zeros(output_dim)\n",
        "        self.lr = 0.01\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        return np.dot(x, self.W) + self.B\n",
        "\n",
        "    def backward(self, delta):\n",
        "        dx = np.dot(delta, self.W.T)\n",
        "        dW = np.dot(self.x.T, delta)\n",
        "        dB = np.sum(delta, axis=0)\n",
        "\n",
        "        self.W -= self.lr * dW\n",
        "        self.B -= self.lr * dB\n",
        "        return dx\n",
        "\n",
        "\n",
        "# Loading MNIST\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Specifying datset size to speed training time\n",
        "x_train = x_train[:1000]\n",
        "y_train = y_train[:1000]\n",
        "\n",
        "# Normalizeing and reshaping to (batch, channel, feature)\n",
        "x_train = x_train.reshape(-1, 1, 28*28).astype(np.float32) / 255.0\n",
        "y_train = to_categorical(y_train)\n",
        "\n",
        "# Model\n",
        "conv_p8 = Conv1d_p8(in_channels=1, out_channels=4, filter_size=5)\n",
        "fc = FC(input_dim=4 *780, output_dim=10)\n",
        "\n",
        "# Trainig loop\n",
        "epochs = 5\n",
        "batch_size = 32\n",
        "num_batches = x_train.shape[0] // batch_size\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    perm = np.random.permutation(x_train.shape[0])\n",
        "    x_train_shuffled = x_train[perm]\n",
        "    y_train_shuffled = y_train[perm]\n",
        "    epoch_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        xb = x_train_shuffled[i*batch_size:(i+1)*batch_size]\n",
        "        yb = y_train_shuffled[i*batch_size:(i+1)*batch_size]\n",
        "\n",
        "        # Forward\n",
        "        out = conv_p8.forward(xb)\n",
        "        out_relu = relu(out)\n",
        "        out_flat = out_relu.reshape(batch_size, -1)\n",
        "        logits = fc.forward(out_flat)\n",
        "        probs = softmax(logits)\n",
        "        loss = cross_entropy(probs, yb)\n",
        "        epoch_loss += loss\n",
        "\n",
        "        pred = np.argmax(probs, axis=1)\n",
        "        true = np.argmax(yb, axis=1)\n",
        "        correct += np.sum(pred == true)\n",
        "\n",
        "        # Backward\n",
        "        dloss = softmax_cross_entropy_grad(probs, yb)\n",
        "        d_fc = fc.backward(dloss)\n",
        "        d_relu = d_fc.reshape(out.shape) * relu_grad(out)\n",
        "        conv_p8.backward(d_relu)\n",
        "\n",
        "    acc = correct / (num_batches * batch_size)\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss/num_batches:.4f} - Accuracy: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNudXoFGzixq",
        "outputId": "e7fbae0e-21d9-481e-a1b1-b7e81cce4e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Loss: 1.9703 - Accuracy: 0.4607\n",
            "Epoch 2/5 - Loss: 1.3305 - Accuracy: 0.7611\n",
            "Epoch 3/5 - Loss: 0.9221 - Accuracy: 0.8165\n",
            "Epoch 4/5 - Loss: 0.7108 - Accuracy: 0.8427\n",
            "Epoch 5/5 - Loss: 0.5979 - Accuracy: 0.8609\n"
          ]
        }
      ]
    }
  ]
}